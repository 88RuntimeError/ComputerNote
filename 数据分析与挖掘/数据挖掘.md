# 数据挖掘

# 一、聚类

## 1. KNN算法

### 1.1 算法原理

**俗语意思：**“近朱者赤，近墨者黑。”、“看一个人什么样，看他身边的朋友什么样就知道了。”

- 通用步骤
  - 计算距离（常用**欧里几德距离 ** 或 **马氏距离**）
  - 升序排列
  - 取前 **K** 个
  - 加权平均

### 1.2 算法优点

**简单易实现：** KNN 算法实际上并没有抽象出任何模型，而是把全部的数据集直接当作模型本身，当一条新数据来了之后跟数据集里面的每一条数据进行对比。所以可以看到 KNN 算法的一些优点，首当其冲的就是这个算法 **简单**，简单到都不需要进行什么训练了，只要把样本数据整理好了，就结束了，来一条新数据就可以进行预测了。

**对于边界不规则的数据效果较好：** 最终的预测是把未知数据作为中心点，然后画一个圈，使得圈里有 K 个数据，所以对于边界不规则的数据，要比线性的分类器效果更好。因为线性分类器可以理解成画一条线来分类，不规则的数据则很难找到一条线将其分成左右两边。

### 1.3 算法缺点

**只适合小数据集：** 正是因为这个算法太简单，每次预测新数据都需要使用全部的数据集，所以如果数据集太大，就会消耗非常长的时间，占用非常大的存储空间。

**数据不平衡效果不好：** 如果数据集中的数据不平衡，有的类别数据特别多，有的类别数据特别少，那么这种方法就会失效了，因为特别多的数据最后在投票的时候会更有竞争优势。

**必须要做数据标准化：** 由于使用距离来进行计算，如果数据量纲不同，数值较大的字段影响就会变大，所以需要对数据进行标准化，比如都转换到 0-1 的区间。

**不适合特征维度太多的数据：** 由于我们只能处理小数据集，如果数据的维度太多，那么样本在每个维度上的分布就很少。比如我们只有三个样本，每个样本只有一个维度，这比每个样本有三个维度特征要明显很多。

### 1.4 精度调整

#### 1.4.1 k值的选取

当 **K越小** 的时候容易 **过拟合**，因为结果的判断与某一个点强相关。

当 **K越大** 的时候容易 **欠拟合**，因为要考虑所有样本的情况，那就等于什么都不考虑。

对于 **K 的取值**，一种显而易见的办法就是从 1 开始**不断地尝试**，查看准确率。随着 K 的增加，一般情况下准确率会先变大后变小，然后选取效果最好的那个 K 值就好了。当然，关于 **K 最好使用奇数**，因为偶数在投票的时候就困难了，如果两个类别的投票数量是一样的，那就没办法抉择了，只能随机选一个。

所以选取一个合适的 K 值也是 KNN 算法在实现时候的一个难点，需要根据经验和效果去进行尝试（**经验** 或 **均方根误差**）。

#### 1.4.2 什么方法计算距离

常用的方法有 **欧里几德距离** 和 **马氏距离**



### 1.5 鸢尾花实战

我们使用一个叫作鸢尾花数据集的数据，这个数据集里面有 150 条数据，共有 3 个类别，即**Setosa 鸢尾花**、**Versicolour 鸢尾花** 和 **Virginica 鸢尾花**，每个类别有 50 条数据，每条数据有 4 个维度，分别记录了鸢尾花的**花萼长度**、**花萼宽度**、**花瓣长度** 和 **花瓣宽度**。



### 1.6 癌症判断实战

```python
import random
import csv

# 读取
with open('Prostate_Cancer.csv','r') as file:
    reader = csv.DictReader(file)
    datas = [row for row in reader]

# 分组
random.shuffle(datas)    # 洗牌
n = len(datas)//3
test_set = datas[0:n]    # 训练集
train_set = datas[n:]    # 测试集


# 距离
def distance(d1, d2):
    res = 0
    for key in ("radius", "texture", "perimeter", "area", "smoothness", "compactness", "symmetry", "fractal_dimension"):
        res += (float(d1[key])-float(d2[key])) ** 2
    return res ** 0.5

# KNN
k = 3
def knn(data):
    # 1.距离
    res = [
        {"result": train['diagnosis_result'], "distance":distance(data, train)}
        for train in train_set
    ]
    # 2.排序：升序
    sorted(res,key=lambda item:item['distance'])
    # 3.取前k个
    res2 = res[0:k]

    # 4.加权平均
    result = {'B':0, 'M':0}
    sum = 0
    # 总距离
    for r in res2:
        sum += r['distance']
    # 计算权重
    for r in res2:
        result[r['result']] += 1 - r['distance']/sum
    if result['B'] > result['M']:
        return 'B'
    else:
        return 'M'

# 测试
correct = 0
for test in test_set:
    result1 = test['diagnosis_result']
    result2 = knn(test)
    if result1 == result2:
        correct += 1
print(correct/len(test_set))
```

